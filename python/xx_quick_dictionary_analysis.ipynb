{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "utility_code/create_features.py:263: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  .sort(inplace=False,columns='i',ascending=False)\\\n",
      "utility_code/create_features.py:266: FutureWarning: sort(columns=....) is deprecated, use sort_values(by=.....)\n",
      "  identity_dat.sort(\"tot\",inplace=True,ascending=False)\n"
     ]
    }
   ],
   "source": [
    "from utility_code.rule_based_features import *\n",
    "from utility_code.util import *\n",
    "from utility_code.create_features import *\n",
    "\n",
    "tw_distant_supervision_identity_dat = get_twitter_distant_supervision_identity_dat(\"../r/output_fil.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = tw_distant_supervision_identity_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = get_stopwords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = tw[tw.term.apply(lambda x: not x in stopwords and not x.replace(\" person\",\"\") in stopwords)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "             term &      tot \\\\\n",
      "\\midrule\n",
      "     black person &  1987792 \\\\\n",
      "     wrong person &   365667 \\\\\n",
      "     young person &   347727 \\\\\n",
      "  favorite person &   273561 \\\\\n",
      "       old person &   268043 \\\\\n",
      "      nice person &   248868 \\\\\n",
      " beautiful person &   235131 \\\\\n",
      "   amazing person &   230198 \\\\\n",
      "       bad person &   223542 \\\\\n",
      "      real person &   219006 \\\\\n",
      "  innocent person &   170849 \\\\\n",
      "    stupid person &   161701 \\\\\n",
      "  homeless person &   156582 \\\\\n",
      "    random person &   156044 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print tw[tw.term.apply(lambda x: ' person' in x)][1:15][['term','tot']].to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = {x.strip() for x in codecs.open('dictionaries/my_dictionaries/identities.txt',\"r\",\"utf8\")}\n",
    "wordnet = {x.strip() for x in codecs.open('dictionaries/my_dictionaries/wordnet_identities.txt',\"r\",\"utf8\")}\n",
    "racial = {x.strip() for x in codecs.open('dictionaries/my_dictionaries/racial_slur_identities.txt',\"r\",\"utf8\")}\n",
    "national = {x.strip() for x in codecs.open('dictionaries/my_dictionaries/national_identities.txt',\"r\",\"utf8\")}\n",
    "job = {x.strip() for x in codecs.open('dictionaries/my_dictionaries/job_identities.txt',\"r\",\"utf8\")}\n",
    "\n",
    "all_wn = {x.strip() for x in codecs.open('all_wordnet_identities_terms.txt',\"r\",\"utf8\")}\n",
    "all_dict = act | wordnet | racial | national | job | all_wn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(930, 8289, 1970, 189, 1567, 12588)"
      ]
     },
     "execution_count": 33,
     "output_type": "execute_result",
     "metadata": {}
    }
   ],
   "source": [
    "len(act), len(wordnet), len(racial), len(national), len(job), len(all_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lr}\n",
      "\\toprule\n",
      "      term &    tot \\\\\n",
      "\\midrule\n",
      "      mess &  94490 \\\\\n",
      "     human &  71371 \\\\\n",
      "    legend &  52867 \\\\\n",
      "      joke &  52579 \\\\\n",
      "     pussy &  51172 \\\\\n",
      "      thot &  47381 \\\\\n",
      "  blessing &  45178 \\\\\n",
      " nightmare &  38819 \\\\\n",
      "  disgrace &  33628 \\\\\n",
      "     cutie &  33478 \\\\\n",
      "    texter &  33067 \\\\\n",
      "   goddess &  32475 \\\\\n",
      "         g &  26668 \\\\\n",
      "       old &  25815 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print tw[tw.term.apply(lambda x: not x in all_dict and not ' person' in x)][1:15][['term','tot']].to_latex(index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}